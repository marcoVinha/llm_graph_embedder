# Fine-Tuning LLaMA 3.3 for Graph-Related Tasks with InstructGLM

This repository explores the use of InstructGLM to fine-tune the LLaMA 3.3 language model for graph-related tasks. The objective is to investigate how well the model performs on tasks such as node-level classification, link prediction and other related stuff.

### Features
- **Fine-tuning Framework**: Implements InstructGLM for task-specific fine-tuning.
- **Evaluation**: Benchmarks LLaMA’s performance on graph datasets to examine the effects of fine-tuning.

### Goals
- To evaluate if bare bones LLMs can be helpful when solving graph-related tasks.
- To explore the potential of using InstructGLM for adapting LLaMA 3.3 to graph-related tasks.
- To evaluate the model’s ability to handle graph-specific problems after fine-tuning.